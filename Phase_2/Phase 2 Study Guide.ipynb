{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "# Data visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# Pre-Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "#Ignore Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOPICS:\n",
    "- Z-Score\n",
    "- PDF/SF\n",
    "- Conferance Intervals\n",
    "       - upper/lower\n",
    "       - interpret it\n",
    "- Null/Alt Hypothesis\n",
    "- Type I/ II Errors\n",
    "- Calculating P-Value\n",
    "- Bayes\n",
    "- Linear Regression\n",
    "- Correlation Matrixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-Score means how many standard deviations away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0013550774889"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's transform the normal distribution centered on 5\n",
    "# with a standard deviation of 2 into a standard normal\n",
    "\n",
    "# Generating our data\n",
    "normal_dist = np.random.normal(loc=5, scale=2, size=1000)\n",
    "\n",
    "np.mean(normal_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.1514348342607266e-17"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, let's standardize by hand\n",
    "# (x - mean) / std\n",
    "z_dist = [(x - np.mean(normal_dist)) / np.std(normal_dist)\n",
    "          for x in normal_dist]\n",
    "\n",
    "np.mean(z_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing a Distribution in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the z-score for that row's HourlyRate\n",
    "(sample_row['HourlyRate'].values[0] - df['HourlyRate'].mean()) / df['HourlyRate'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the column\n",
    "mu = df['HourlyRate'].mean()\n",
    "sigma = df['HourlyRate'].std()\n",
    "standardized_rate = [(x-mu)/sigma for x in df['HourlyRate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Margin of Error = Critical Value * Sample Standard Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Critical Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need ùõº\n",
    "<br>\n",
    "ùõº=1‚àíConfidence Level\n",
    "<br>\n",
    "So, if you pick a 95% confidence level, then  ùõº  = 1 - .95 = .05\n",
    "<br>\n",
    "BUT because you want to be confident on either side, this actually ends up being divided by 2!\n",
    ".05/2=.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the percentage of \"acceptable\" error on either side.\n",
    "<br>\n",
    "Why does this matter? Because you'll feed this value into your search for your critical value - a value which comes from the probability at the point at which there's 2.5% on each side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITTEN OUT VERSION\n",
    "\n",
    "#80%-confidence interval\n",
    "n = 30\n",
    "x_bar = 2000\n",
    "s = 200\n",
    "\n",
    "alpha80 = 1 - .80\n",
    "\n",
    "#Want confidence on both sides of the curve\n",
    "# 1 - (alpha80/2) = 0.9\n",
    "\n",
    "#calculate t-values\n",
    "t_value80 = stats.t.ppf(0.9, n-1)\n",
    "\n",
    "#calculate t-margins of error\n",
    "margin_error80 = t_value80 * 200/(n**0.5)\n",
    "#RAISED TO 0.5 IS THE SQUARE ROOT\n",
    "\n",
    "#calculate 80%-intervals\n",
    "conf_int80 = (x_bar - margin_error80, x_bar + margin_error80)\n",
    "\n",
    "#print out results\n",
    "print(conf_int80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK THE ABOVE USING THE VERSION BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-acca117e39db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Of course, there's also: USE THIS TO CHECK HARD CODED WORK ON CODE CHALLENGE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m stats.t.interval(alpha=0.95,\n\u001b[0m\u001b[1;32m      3\u001b[0m                  \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HourlyRate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  df=n-1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "# Of course, there's also: USE THIS TO CHECK HARD CODED WORK ON CODE CHALLENGE\n",
    "stats.t.interval(alpha=0.95,\n",
    "                 loc = sample_mean,\n",
    "                 scale = stats.sem(sample['HourlyRate']),\n",
    "                 df=n-1)\n",
    "\n",
    "\n",
    "#Alpha really means be confidence \n",
    "#Scale is getting the sem (standard error of the mean)\n",
    "\n",
    "#THIS GIVES US THE CONFIDENCE INTERVAL AT 95% Confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPOTHESIS TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is at heart what hypothesis testing is: *\"Does our sample come from the population or is it a special set?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a _threshold value_ $\\alpha$ (called the **significance level** or **False Positive Rate**) helps to decide whether we believe that the sample is from the same underlying population or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps of a Hypothesis Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. State the null hypothesis and the alternative hypothesis\n",
    "2. Specify significance level ($\\alpha$)\n",
    "3. Calculate test statistic (z-statistic, t- statistic, etc.)\n",
    "4. Calculate p-value\n",
    "5. Interpret p-value (reject or fail to reject the null hypothesis) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating P-Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the Z-Score is Positive: for the $z$-test, we can use the CDF of the normal distribution to find this probability (`p = 1 - scipy.stats.norm.cdf(z_score)`). Shortcut: `p = scipy.stats.norm.sf(z_score)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $p \\lt \\alpha$, we reject the null hypothesis.:\n",
    "\n",
    "If $p \\geq \\alpha$, we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also caluclate the P value using `p = stats.norm.sf(z_score)` which is the opposite `p = 1 - scipy.stats.norm.cdf(z_score)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA for multiple groups before ANOVA Testing to compare multiple samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the mean and std for every group\n",
    "\n",
    "df.groupby('Column Name').agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F- Statistic:\n",
    "The higher the F- Statistic, the lower the P-Value so it is more likely you reject the null hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chi Square Tests-  about frequencies (counts) for discrete variables (categorical data). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used when frequency > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goodness of Fit Test: 1 categorical variable, which could have subclasses. Testing 1 category with 1 or more changes. (Not looking for a relationship between classes but looking to compare Expectations (Control) and Observations (Experiment/Variation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independent Test: 2 or more categorical variables. Each category may have subclasses.\n",
    "Testing realtionship between multiple categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting coefficients: <br>\n",
    "Intercept: Mean of your target variable/column (aka baseline) (value of Y/dependent variable when X/independent variable is 0)<br>\n",
    "X: For every increase of 1 in X there is an increase of NUMBER in the target variable <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = df.drop(\"target\", axis =1)\n",
    "#Add constant\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "#Create Target Variable\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Instantiate model\n",
    "model = sm.OLS(endog = y, exog = X)\n",
    "\n",
    "#Fit model - Pulls Mean and STD from data since it's parametric model\n",
    "model = model.fit()\n",
    "model.summary()\n",
    "\n",
    "#Transform or Scale \n",
    "\n",
    "\n",
    "#Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALING (Not neccessary for a standard Linear Regression Model)<br>\n",
    "For every increase in 1 standard deviation of independent variable, there is an increase in the dependent variable shown in the standardized coefficient values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing/Normalizing the Independent Variables is equivalent to getting the Z-Scores of every variable\n",
    "\n",
    "(X - X.mean()) / np.std(X)\n",
    "\n",
    "#Can use SKLearn Standard Scaler\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)\n",
    "X_standardized_train = ss.transform(X_train)\n",
    "X_standardized_test = ss.transform(X_test)\n",
    "\n",
    "#CHECKING STANDARD SCALER WORKED- MEANS should be close to 0 and STD should be close to 1\n",
    "X_standardized_train.mean(axis = 0)\n",
    "\n",
    "X_standardized_train.std(axis = 0)\n",
    "\n",
    "X_standardized_test.mean(axis = 0)\n",
    "\n",
    "X_standardized_test.std(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLearn's Standard Scaler- Standardizing a distribution (going to be very important for Machine Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEVER FIT ON TEST OR VALIDATION DATA. ONLY FIT ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing StandardScaler from the preprocessing module\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Need to instantiate our scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting our scaler (note how we need to make the column into a dataframe)\n",
    "scaler.fit(df[['HourlyRate']])\n",
    "\n",
    "# Grabbing the transformed values out as scaled_rate\n",
    "scaled_rate = scaler.transform(df[['HourlyRate']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-deff564a6677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#MEAN ABSOLUTE ERROR - in the same units as my target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwine_preds_st_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#ROOT MEAN SQUARED ERROR - in the same units as my target variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "#MEAN ABSOLUTE ERROR - in the same units as my target variable\n",
    "metrics.mean_absolute_error(wine_target, lr.predict(wine_preds_st_scaled))\n",
    "\n",
    "\n",
    "#ROOT MEAN SQUARED ERROR - in the same units as my target variable\n",
    "metrics.mean_squared_error(wine_target, lr.predict(wine_preds_st_scaled), squared = False)\n",
    "\n",
    "#MEAN SQUARED ERROR\n",
    "metrics.mean_squared_error(wine_target, lr.predict(wine_preds_st_scaled), squared = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoiding Multicollinearity\n",
    "\n",
    "A further assumption for multiple linear regression is that the predictors/x variables are independent.\n",
    "\n",
    "#### VIEWING CORRELATION AND USING A HEATMAP (from Feture Selection Lecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the .corr() DataFrame method to find out about the\n",
    "# correlation values between all pairs of variables!\n",
    "\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(14, 14)})\n",
    "\n",
    "# Use the .heatmap function to depict the relationships visually!\n",
    "sns.heatmap(df.corr(),annot=True);\n",
    "\n",
    "#Want to check that 1 predictive variable is not correlated with another predictive variable. Need to be independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a predictor/X Variable has the largest correlation w target/Y Variable, then it will also have the largest coefficient- meaning a change of 1 unit in X will have the largest change in Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
